{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### opt main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import gurobipy as grb\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Please change the following path\n",
    "cp = 'PATH'\n",
    "\n",
    "# merge dataframe\n",
    "## hazard scenario\n",
    "df1 = pd.read_csv(cp + '/in/multihazard_all.csv',encoding='utf-8')\n",
    "df1 = df1.fillna(0)\n",
    "df1.loc[:, 'ID'] = df1['ID'].astype(str)\n",
    "\n",
    "## Toyokawa levee breach scenario and available land\n",
    "df = pd.read_csv(cp + '/in/multi_hazard.csv',encoding='utf-8')\n",
    "df = df.fillna(0)\n",
    "df.loc[:, 'ID'] = df['ID'].astype(str)\n",
    "\n",
    "## Land price data\n",
    "chika = pd.read_csv('../LandPrice/out/estimated_chika.csv',encoding = 'utf-8')\n",
    "dfrt = chika.fillna(0)\n",
    "dfrt.loc[:, 'ID'] = dfrt['ID'].astype(str)\n",
    "\n",
    "## Merge levee breach scenario data, hazard scenario data, and land price data\n",
    "df_merge = pd.merge(df, df1, left_on = 'ID', right_on = 'ID')\n",
    "df_mergert = pd.merge(df_merge, dfrt, left_on = 'ID', right_on = 'ID')\n",
    "df = df_mergert\n",
    "df = df.drop_duplicates(subset=['ID']).reset_index(drop=True)\n",
    "df = df.fillna(0)\n",
    "\n",
    "## Add a Toyokawa hazard scenario 'equal'\n",
    "df['equal'] = (df[['mh01', 'mh02', 'mh03', 'mh04', 'mh06', 'mh07']] == 1).any(axis=1).astype(int)\n",
    "\n",
    "# Flood occurence probability pattern\n",
    "dfh = pd.read_csv(cp + '/in/p_H.csv')\n",
    "dfh = dfh.fillna(0)\n",
    "\n",
    "# Probability p_s^B of 7 scenarios of levee breach\n",
    "dfs = pd.read_csv(cp + '/in/p_sB.csv')\n",
    "dfs = dfs.fillna(0)\n",
    "\n",
    "# Effectiveness of proximity\n",
    "dfe = pd.read_csv(cp + '/in/alpha.csv')\n",
    "\n",
    "# original area data\n",
    "df2 = pd.read_csv(cp + '/in/Toyohashi_area_x0_original.csv')\n",
    "df2 = df2.fillna(0)\n",
    "\n",
    "# A blanck data frame for optimised land use result\n",
    "df3 = pd.read_csv(cp + '/in/opthere.csv')\n",
    "\n",
    "## Dataframe for the output csv\n",
    "cols = ['h','s','e','q','val.opt']\n",
    "dfval = pd.DataFrame(index=[], columns=cols)\n",
    "\n",
    "## index for grid row ID\n",
    "Q = 0\n",
    "\n",
    "# To Numpy\n",
    "hazard = dfh.values\n",
    "sB = dfs.values\n",
    "effect = dfe.values\n",
    "\n",
    "# Scenario Settings to run !! Please change the range accoring to which scenario you want to see\n",
    "## Number of dataframe\n",
    "number = df['ALAND']\n",
    "\n",
    "# Hazard = range(0,len(hazard))\n",
    "# Scenario = range(0,len(sB[0]))\n",
    "# # Effect = range(0,len(effect))\n",
    "# Effect = [0,5]\n",
    "\n",
    "Hazard = [0,1,2,3]\n",
    "Scenario = [0,1,2,3,4,5,6]\n",
    "# Effect = range(0,len(effect))\n",
    "Effect = [0,3,5]\n",
    "\n",
    "## \n",
    "T = 30\n",
    "I = range(0,len(number))\n",
    "nK = 3\n",
    "K = range(0,nK)\n",
    "\n",
    "beta = 0.95\n",
    "\n",
    "#management cost = 10,4919 JPY\n",
    "# mc = [235405,50000,100000,200000,300000,400000,500000,600000,700000]\n",
    "mc = [235405,50000,300000]\n",
    "\n",
    "# Uncomment below if you want to calculate the value of objective function for original land use\n",
    "#mc = [1000000000000]\n",
    "\n",
    "# なぜこれが111でよいのかチェックする\n",
    "alpha = [1,1,1]\n",
    "\n",
    "# Delete the original land use area data if the grid is UNAVAILABLE area\n",
    "# 5-15% areas will be deleted due to data consistency\n",
    "df2['L'] = df2['NL']*df['ALAND']\n",
    "df2['S'] = df2['NS']*df['ALAND']\n",
    "df2['M'] = df2['NM']*df['ALAND']\n",
    "dfm = df2.filter(items=['L','S','M'])\n",
    "AA = dfm.values\n",
    "d1 = dfm.iloc[:,0]\n",
    "d2 = dfm.iloc[:,1]\n",
    "d3 = dfm.iloc[:,2]\n",
    "\n",
    "# Making dataframe of maximum areas per grid \n",
    "## Total areas = 100 m^2 \n",
    "A = 10000 #MAX\n",
    "Ava = df['ALAND']*A\n",
    "\n",
    "## Total areas for each land use\n",
    "D = [np.sum(d1),np.sum(d2),np.sum(d3)] #TOTAL\n",
    "\n",
    "column_list = ['equal','mh01', 'mh02', 'mh03', 'mh04', 'mh06', 'mh07']\n",
    "#column_list = ['umetagaw_1','yagyuuga_1','sanagawa_S','otowa_S_ne','kamita_S_s','sakai_S_ne','takasio_ne']\n",
    "\n",
    "for q in [0]: # For each shrinking/expanding cost parameter settings\n",
    "\n",
    "    ck = [48000,48000,48000]\n",
    "    hk = [mc[q],mc[q],mc[q]]\n",
    "    dk = [mc[q],mc[q],mc[q]]\n",
    "    # ck = [45000,45000,45000]\n",
    "    # hk = [5000,5000,100000]\n",
    "    # dk = [5000,5000,100000]\n",
    "\n",
    "    for h in Hazard: # For each flood occurence scenario 0, 0.03, 1\n",
    " \n",
    "        for s in Scenario: # For each levee breach scenario\n",
    "            h_flag = True\n",
    "            #print(s)\n",
    "            for e in Effect: # For each proximity effect scenario\n",
    "                if h_flag: # A flag that represents if this is the first round of for e in Effect\n",
    "\n",
    "                    # land price\n",
    "                    df1 = df\n",
    "\n",
    "                    # probability changed by scenario\n",
    "                    H = hazard[h] # flood occurence probability\n",
    "                    p = H*sB[0][s]*df1[column_list[s]]\n",
    "\n",
    "                    Scenarios = []\n",
    "                    # Pre-disaster land price\n",
    "                    p_land_cols = ['if_jukyo', 'if_shogyo', 'if_kogyo']\n",
    "\n",
    "                    # Post-disaster land price\n",
    "                    for col in p_land_cols:\n",
    "                        df1.loc[:, col + '_dmg'] = df1[col].copy()  # Copy Pre-\n",
    "                        df1.loc[df1[column_list[s]] > 0, col + '_dmg'] = 0.8 * df1[col]  # Update to Post-\n",
    "\n",
    "                    # New Land price dataframe\n",
    "                    #df_0 = df1[[col for col in p_land_cols] + [col + '_dmg' for col in p_land_cols]]\n",
    "                    df_0 = df1[[col for col in p_land_cols] + [col + '_dmg' for col in p_land_cols]].copy()\n",
    "                    \n",
    "                    name_s = 'exp_Lprice_' + column_list[s]\n",
    "                    for col in p_land_cols:\n",
    "                        df1[f'exp_Lprice_{column_list[s]}_{col}_{h}_{s}'] = ((1-pow(beta,T))/(1-beta))*df_0[col] - (df_0[col] - df_0[col + '_dmg'])*p*((1-pow(beta,T))/(1-beta)) - T*pow(beta,T)\n",
    "                    temp_columns = [f'exp_Lprice_{column_list[s]}_{col}_{h}_{s}' for col in p_land_cols]\n",
    "                    dfr = pd.concat([df1[temp_columns]], axis=1)\n",
    "                    r = dfr.values\n",
    "\n",
    "                    h_flag = False\n",
    "\n",
    "                model = grb.Model('wcs')\n",
    "                x,y,z,Z = {}, {}, {}, {}\n",
    "                for i in I:\n",
    "                    for k in K:\n",
    "                        x[i,k] = model.addVar(vtype = 'C', lb = 0)\n",
    "                for i in I:\n",
    "                    for k in K:\n",
    "                        y[i,k] = model.addVar(vtype = 'C', lb = 0)\n",
    "                for i in I:\n",
    "                    for k in K:\n",
    "                        z[i,k] = model.addVar(vtype = 'C', lb = 0)\n",
    "                #print(len(I))\n",
    "                for i in I:\n",
    "                    model.addConstr(grb.quicksum(x[i,k] for k in K) <= Ava[i])\n",
    "\n",
    "                for k in K:\n",
    "                    #print(x[i,k])\n",
    "                    model.addConstr(grb.quicksum(x[i,k] for i in I) == D[k])\n",
    "                df_net = pd.read_csv(cp + '/in/neighbourhood.csv', header = None)\n",
    "\n",
    "                L = range(4)\n",
    "                for i in I:\n",
    "                    for k in K:\n",
    "                        wa = 0\n",
    "                        for l in L:\n",
    "                            if df_net.iloc[i,l] >= 0:\n",
    "                                a = df_net.iloc[i,l]\n",
    "                                b = x[a,k]*effect[e]\n",
    "                                wa = wa + b\n",
    "                                Z[i,k] = wa\n",
    "                for i in I:\n",
    "                    for k in K:\n",
    "                        model.addConstr(y[i,k] >= hk[k]*(x[i,k] - AA[i,k]))\n",
    "                        model.addConstr(y[i,k] >= dk[k]*(-x[i,k] + AA[i,k]))\n",
    "                        model.addConstr(z[i,k] <= alpha[k]*ck[k]*Z[i,k])\n",
    "                        model.addConstr(z[i,k] - ck[k]*x[i,k] <= 0)\n",
    "\n",
    "                model.setObjective(grb.quicksum(r[i,k]*x[i,k] for i in I for k in K) - grb.quicksum(ck[k]*x[i,k]-z[i,k]for i in I for k in K)  - grb.quicksum(y[i,k] for i in I for k in K), grb.GRB.MAXIMIZE)\n",
    "\n",
    "                model.optimize()\n",
    "\n",
    "                # Uncomment below for output Zij\n",
    "                # cols = ['zij','i','j']\n",
    "                # dfc = pd.DataFrame(index=[], columns=cols)\n",
    "                # for k in K:\n",
    "                #     dfc = pd.DataFrame(index=[], columns=cols)\n",
    "                #     q = 0\n",
    "                #     for i in I:\n",
    "                #         wa = 0\n",
    "                #         for l in L:\n",
    "                #             if df_net.iloc[i,l] >= 0:\n",
    "                #                  a = df_net.iloc[i,l]\n",
    "                #                  if x[a,k].X > 0:\n",
    "                #                      dfc.loc[q,'zij'] = x[a,k].X\n",
    "                #                      dfc.loc[q,'i'] = i\n",
    "                #                      dfc.loc[q,'j'] = a\n",
    "                #                      q += 1\n",
    "                #     dfc.to_csv(cp + '/out_01/Zij/Zij'+str(h)+str(s)+str(e)+str(k)+'.csv')\n",
    "\n",
    "                df3.loc[I, 'optL'] = [x[i, 0].X for i in I]\n",
    "                df3.loc[I, 'optS'] = [x[i, 1].X for i in I]\n",
    "                df3.loc[I, 'optM'] = [x[i, 2].X for i in I]\n",
    "                df3.loc[I, 'optL_diff'] = [AA[i,0]-x[i,0].X for i in I]\n",
    "                df3.loc[I, 'optS_diff'] = [AA[i,1]-x[i,1].X for i in I]\n",
    "                df3.loc[I, 'optM_diff'] = [AA[i,2]-x[i,2].X for i in I]\n",
    "                \n",
    "                # Output of the optimal value of original lanse use\n",
    "                #df3.to_csv(cp + '/out_01/f/f9999.csv',index=False)\n",
    "\n",
    "                # Output optimal land use\n",
    "                df3.to_csv(cp + '/out_01/f/f' +str(h)+str(s)+str(e)+str(q)+'.csv',index=False)\n",
    "                print(f'the file name is {h} {s} {e} {q}')\n",
    "\n",
    "                val_opt = model.ObjVal\n",
    "                dfval.loc[Q,'h'] = str(h)\n",
    "                dfval.loc[Q,'s'] = str(s)\n",
    "                dfval.loc[Q,'e'] = str(e)\n",
    "                dfval.loc[Q,'q'] = str(q)\n",
    "                dfval.loc[Q,'val.opt'] = val_opt\n",
    "                Q += 1\n",
    "\n",
    "# Output of the optimal value of original lanse use\n",
    "#dfval.to_csv(cp +'/out_01/optvalorg.csv')\n",
    "\n",
    "# Output optimal land use\n",
    "dfval.to_csv(cp +'/out_01/optval.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Land Use\n",
    " - The original land use is calculated by setting a Big mc (demolish/counstruction cost) to avoid allocating areas to grids different from the current grids.\n",
    "- mc = 10,000,000,000,000,000\n",
    "- mc is supposed that it is not actually cost, so please be aware that the optimal allocations are exactly same as the original allocations.\n",
    "- If there are differences between the original land use and the optimal land use, just sum the all differences.abs and multiply mc for calculating the cost 'that is not supposed to be cost'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import gurobipy as grb\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Please change the following path\n",
    "cp = 'PATH'\n",
    "\n",
    "# merge dataframe\n",
    "## hazard scenario\n",
    "df1 = pd.read_csv(cp + '/in/multihazard_all.csv',encoding='utf-8')\n",
    "df1 = df1.fillna(0)\n",
    "df1.loc[:, 'ID'] = df1['ID'].astype(str)\n",
    "\n",
    "## Toyokawa levee breach scenario and available land\n",
    "df = pd.read_csv(cp + '/in/multi_hazard.csv',encoding='utf-8')\n",
    "df = df.fillna(0)\n",
    "df.loc[:, 'ID'] = df['ID'].astype(str)\n",
    "\n",
    "## Land price data\n",
    "chika = pd.read_csv('../LandPrice/out/estimated_chika.csv',encoding = 'utf-8')\n",
    "dfrt = chika.fillna(0)\n",
    "dfrt.loc[:, 'ID'] = dfrt['ID'].astype(str)\n",
    "\n",
    "## Merge levee breach scenario data, hazard scenario data, and land price data\n",
    "df_merge = pd.merge(df, df1, left_on = 'ID', right_on = 'ID')\n",
    "df_mergert = pd.merge(df_merge, dfrt, left_on = 'ID', right_on = 'ID')\n",
    "df = df_mergert\n",
    "df = df.drop_duplicates(subset=['ID']).reset_index(drop=True)\n",
    "df = df.fillna(0)\n",
    "\n",
    "## Add a Toyokawa hazard scenario 'equal'\n",
    "df['equal'] = (df[['mh01', 'mh02', 'mh03', 'mh04', 'mh06', 'mh07']] == 1).any(axis=1).astype(int)\n",
    "\n",
    "# Flood occurence probability pattern\n",
    "dfh = pd.read_csv(cp + '/in/p_H.csv')\n",
    "dfh = dfh.fillna(0)\n",
    "\n",
    "# Probability p_s^B of 7 scenarios of levee breach\n",
    "dfs = pd.read_csv(cp + '/in/p_sB.csv')\n",
    "dfs = dfs.fillna(0)\n",
    "\n",
    "# Effectiveness of proximity\n",
    "dfe = pd.read_csv(cp + '/in/alpha.csv')\n",
    "\n",
    "# original area data\n",
    "df2 = pd.read_csv(cp + '/in/Toyohashi_area_x0_original.csv')\n",
    "df2 = df2.fillna(0)\n",
    "\n",
    "# A blanck data frame for optimised land use result\n",
    "df3 = pd.read_csv(cp + '/in/opthere.csv')\n",
    "\n",
    "## Dataframe for the output csv\n",
    "cols = ['h','s','e','q','val.opt']\n",
    "dfval = pd.DataFrame(index=[], columns=cols)\n",
    "\n",
    "## index for grid row ID\n",
    "Q = 0\n",
    "\n",
    "# To Numpy\n",
    "hazard = dfh.values\n",
    "sB = dfs.values\n",
    "effect = dfe.values\n",
    "\n",
    "# Scenario Settings to run !! Please change the range accoring to which scenario you want to see\n",
    "## Number of dataframe\n",
    "number = df['ALAND']\n",
    "\n",
    "# Hazard = range(0,len(hazard))\n",
    "# Scenario = range(0,len(sB[0]))\n",
    "# # Effect = range(0,len(effect))\n",
    "# Effect = [0,5]\n",
    "\n",
    "# Hazard = [0,1,2,3]\n",
    "# Scenario = [0,1,2,3,4,5,6]\n",
    "# # Effect = range(0,len(effect))\n",
    "# Effect = [0,3,5]\n",
    "\n",
    "Hazard = [3]\n",
    "Scenario = [0]\n",
    "# Effect = range(0,len(effect))\n",
    "Effect = [0]\n",
    "\n",
    "## \n",
    "T = 30\n",
    "I = range(0,len(number))\n",
    "nK = 3\n",
    "K = range(0,nK)\n",
    "\n",
    "beta = 0.95\n",
    "\n",
    "#management cost = 10,4919 JPY\n",
    "# mc = [235405,50000,100000,200000,300000,400000,500000,600000,700000]\n",
    "# mc = [235405,50000,300000]\n",
    "\n",
    "# Uncomment below if you want to calculate the value of objective function for original land use\n",
    "mc = [10000000000]\n",
    "\n",
    "# なぜこれが111でよいのかチェックする\n",
    "alpha = [1,1,1]\n",
    "\n",
    "# Delete the original land use area data if the grid is UNAVAILABLE area\n",
    "# 5-15% areas will be deleted due to data consistency\n",
    "df2['L'] = df2['NL']*df['ALAND']\n",
    "df2['S'] = df2['NS']*df['ALAND']\n",
    "df2['M'] = df2['NM']*df['ALAND']\n",
    "dfm = df2.filter(items=['L','S','M'])\n",
    "AA = dfm.values\n",
    "d1 = dfm.iloc[:,0]\n",
    "d2 = dfm.iloc[:,1]\n",
    "d3 = dfm.iloc[:,2]\n",
    "\n",
    "# Making dataframe of maximum areas per grid \n",
    "## Total areas = 100 m^2 \n",
    "A = 10000 #MAX\n",
    "Ava = df['ALAND']*A\n",
    "\n",
    "## Total areas for each land use\n",
    "D = [np.sum(d1),np.sum(d2),np.sum(d3)] #TOTAL\n",
    "\n",
    "column_list = ['equal','mh01', 'mh02', 'mh03', 'mh04', 'mh06', 'mh07']\n",
    "#column_list = ['umetagaw_1','yagyuuga_1','sanagawa_S','otowa_S_ne','kamita_S_s','sakai_S_ne','takasio_ne']\n",
    "\n",
    "start_time = time.time()\n",
    "for q in [0]: # For each shrinking/expanding cost parameter settings\n",
    "\n",
    "    ck = [48000,48000,48000]\n",
    "    hk = [mc[q],mc[q],mc[q]]\n",
    "    dk = [mc[q],mc[q],mc[q]]\n",
    "    # ck = [45000,45000,45000]\n",
    "    # hk = [5000,5000,100000]\n",
    "    # dk = [5000,5000,100000]\n",
    "\n",
    "    for h in Hazard: # For each flood occurence scenario 0, 0.03, 1\n",
    " \n",
    "        for s in Scenario: # For each levee breach scenario\n",
    "            h_flag = True\n",
    "            #print(s)\n",
    "            for e in Effect: # For each proximity effect scenario\n",
    "                if h_flag: # A flag that represents if this is the first round of for e in Effect\n",
    "\n",
    "                    # land price\n",
    "                    df1 = df\n",
    "\n",
    "                    # probability changed by scenario\n",
    "                    H = hazard[h] # flood occurence probability\n",
    "                    p = H*sB[0][s]*df1[column_list[s]]\n",
    "\n",
    "                    Scenarios = []\n",
    "                    # Pre-disaster land price\n",
    "                    p_land_cols = ['if_jukyo', 'if_shogyo', 'if_kogyo']\n",
    "\n",
    "                    # Post-disaster land price\n",
    "                    for col in p_land_cols:\n",
    "                        df1.loc[:, col + '_dmg'] = df1[col].copy()  # Copy Pre-\n",
    "                        df1.loc[df1[column_list[s]] > 0, col + '_dmg'] = 0.8 * df1[col]  # Update to Post-\n",
    "\n",
    "                    # New Land price dataframe\n",
    "                    #df_0 = df1[[col for col in p_land_cols] + [col + '_dmg' for col in p_land_cols]]\n",
    "                    df_0 = df1[[col for col in p_land_cols] + [col + '_dmg' for col in p_land_cols]].copy()\n",
    "                    \n",
    "                    name_s = 'exp_Lprice_' + column_list[s]\n",
    "                    for col in p_land_cols:\n",
    "                        df1[f'exp_Lprice_{column_list[s]}_{col}_{h}_{s}'] = ((1-pow(beta,T))/(1-beta))*df_0[col] - (df_0[col] - df_0[col + '_dmg'])*p*((1-pow(beta,T))/(1-beta)) - T*pow(beta,T)\n",
    "                    temp_columns = [f'exp_Lprice_{column_list[s]}_{col}_{h}_{s}' for col in p_land_cols]\n",
    "                    dfr = pd.concat([df1[temp_columns]], axis=1)\n",
    "                    r = dfr.values\n",
    "\n",
    "                    h_flag = False\n",
    "\n",
    "                model = grb.Model('wcs')\n",
    "                x,y,z,Z = {}, {}, {}, {}\n",
    "                for i in I:\n",
    "                    for k in K:\n",
    "                        x[i,k] = model.addVar(vtype = 'C', lb = 0)\n",
    "                for i in I:\n",
    "                    for k in K:\n",
    "                        y[i,k] = model.addVar(vtype = 'C', lb = 0)\n",
    "                for i in I:\n",
    "                    for k in K:\n",
    "                        z[i,k] = model.addVar(vtype = 'C', lb = 0)\n",
    "                #print(len(I))\n",
    "                for i in I:\n",
    "                    model.addConstr(grb.quicksum(x[i,k] for k in K) <= Ava[i])\n",
    "\n",
    "                for k in K:\n",
    "                    #print(x[i,k])\n",
    "                    model.addConstr(grb.quicksum(x[i,k] for i in I) == D[k])\n",
    "                df_net = pd.read_csv(cp + '/in/neighbourhood.csv', header = None)\n",
    "\n",
    "                L = range(4)\n",
    "                for i in I:\n",
    "                    for k in K:\n",
    "                        wa = 0\n",
    "                        for l in L:\n",
    "                            if df_net.iloc[i,l] >= 0:\n",
    "                                a = df_net.iloc[i,l]\n",
    "                                b = x[a,k]*effect[e]\n",
    "                                wa = wa + b\n",
    "                                Z[i,k] = wa\n",
    "                for i in I:\n",
    "                    for k in K:\n",
    "                        model.addConstr(y[i,k] >= hk[k]*(x[i,k] - AA[i,k]))\n",
    "                        model.addConstr(y[i,k] >= dk[k]*(-x[i,k] + AA[i,k]))\n",
    "                        model.addConstr(z[i,k] <= alpha[k]*ck[k]*Z[i,k])\n",
    "                        model.addConstr(z[i,k] - ck[k]*x[i,k] <= 0)\n",
    "\n",
    "                model.setObjective(grb.quicksum(r[i,k]*x[i,k] for i in I for k in K) - grb.quicksum(ck[k]*x[i,k]-z[i,k]for i in I for k in K)  - grb.quicksum(y[i,k] for i in I for k in K), grb.GRB.MAXIMIZE)\n",
    "\n",
    "                model.optimize()\n",
    "\n",
    "                # Uncomment below for output Zij\n",
    "                # cols = ['zij','i','j']\n",
    "                # dfc = pd.DataFrame(index=[], columns=cols)\n",
    "                # for k in K:\n",
    "                #     dfc = pd.DataFrame(index=[], columns=cols)\n",
    "                #     q = 0\n",
    "                #     for i in I:\n",
    "                #         wa = 0\n",
    "                #         for l in L:\n",
    "                #             if df_net.iloc[i,l] >= 0:\n",
    "                #                  a = df_net.iloc[i,l]\n",
    "                #                  if x[a,k].X > 0:\n",
    "                #                      dfc.loc[q,'zij'] = x[a,k].X\n",
    "                #                      dfc.loc[q,'i'] = i\n",
    "                #                      dfc.loc[q,'j'] = a\n",
    "                #                      q += 1\n",
    "                #     dfc.to_csv(cp + '/out_01/Zij/Zij'+str(h)+str(s)+str(e)+str(k)+'.csv')\n",
    "\n",
    "                # df3.loc[I, 'optL'] = [x[i, 0].X for i in I]\n",
    "                # df3.loc[I, 'optS'] = [x[i, 1].X for i in I]\n",
    "                # df3.loc[I, 'optM'] = [x[i, 2].X for i in I]\n",
    "                # df3.loc[I, 'optL_diff'] = [AA[i,0]-x[i,0].X for i in I]\n",
    "                # df3.loc[I, 'optS_diff'] = [AA[i,1]-x[i,1].X for i in I]\n",
    "                # df3.loc[I, 'optM_diff'] = [AA[i,2]-x[i,2].X for i in I]\n",
    "                sum_y = sum(y[i,k].X for i in I for k in K)\n",
    "                                \n",
    "                # Output of the optimal value of original lanse use\n",
    "                #df3.to_csv(cp + '/out_01/f/f9999.csv',index=False)\n",
    "\n",
    "                # Output optimal land use\n",
    "                # df3.to_csv(cp + '/out_01/f/t' +str(h)+str(s)+str(e)+str(q)+'.csv',index=False)\n",
    "                # print(f'the file name is {h} {s} {e} {q}')\n",
    "\n",
    "                val_opt = model.ObjVal\n",
    "                dfval.loc[Q,'h'] = str(h)\n",
    "                dfval.loc[Q,'s'] = str(s)\n",
    "                dfval.loc[Q,'e'] = str(e)\n",
    "                dfval.loc[Q,'q'] = str(q)\n",
    "                dfval.loc[Q,'val.opt'] = val_opt + sum_y\n",
    "                Q += 1\n",
    "\n",
    "# Output of the optimal value of original lanse use\n",
    "#dfval.to_csv(cp +'/out_01/optvalorg.csv')\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Simulation time: {elapsed_time} seconds\")\n",
    "\n",
    "# # Output optimal land use\n",
    "# dfval.to_csv(cp +'/out_01/optvalt.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
